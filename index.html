<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">
  <script async defer src="https://buttons.github.io/buttons.js"></script>

  <title>:: Vivswan ::</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">

    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Vivswan Shitole</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile1.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#projects">Projects</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#experience">Experience</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#education">Education</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#skills">Skills</a>
        </li>
        <!-- <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#interests">Interests</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>
        </li> -->
      </ul>

    </div>

    <div class="social-icons">
      <a href="https://www.linkedin.com/in/vivswan-shitole-a0287964/" target="_blank">
        <i class="fab fa-linkedin-in"></i>
      </a>
      <a href="https://github.com/viv92" target="_blank">
        <i class="fab fa-github"></i>
      </a>
      <!--<a href="#">
        <i class="fab fa-twitter"></i>
      </a>-->
      <!--<a href="https://www.facebook.com/vivswan.shitole" target="_blank">
        <i class="fab fa-facebook-f"></i>
      </a>-->
      <a href="https://scholar.google.com/citations?user=sgBg3_UAAAAJ&hl=en&oi=ao" target="_blank">
        <i class="fas fa-graduation-cap"></i>
      </a>
    </div>

  </nav>

  <div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100">
        <h1 class="mb-0"> Vivswan
        <span class="text-primary"> Shitole </h1>

        <div class="subheading mb-5"><!-- · Graduate Researcher · Oregon State University · Machine Learning Engineer · Aitoe Labs · Software Engineer · Texas Instruments · Researcher · IIT Bombay · --> AI Researcher <br/>
          <a href="mailto:shitolev@oregonstate.edu">shitolev@oregonstate.edu</a>
        </div>

        <!--<p class="lead mb-5">Hi! I am Vivswan. I am currently a Graduate Research Assistant working on Explainable Artificial Intelligence under Dr. Prasad Tadepalli and Dr. Alan Fern at Oregon State University. Before that I took a Computer Vision based surveillance Startup from zero to one, being one of the first five employees at Aitoe Labs. Around the same time I worked on Video Search and Summarization as a reseacher under Dr. Ganesh Ramakrishnan and Dr. Rishabh Iyer at Indian Institute of Technology Bombay. In previous life I worked on Surround View for Advanced Driver Assistant System, SafeTI Library adhering to ASIL-B standard and Bluetooth Low Energy Software Stack as a Software Engineer at Texas Instruments.</p>-->

        <p class="lead mb-5">I am currently a Graduate Research Assistant working on Explainable Artificial Intelligence under Dr. Prasad Tadepalli at Oregon State University. I have hands-on research and industry experience on several facets of AI and Machine Learning. My works span across:
          <ul class="body_ul" style="list-style-type:square">
            <li>Computer Vision for Object Tracking and surveillance using Deep Learning</li>
            <li>Discrete Event Simulation Optimization using Deep Reinforcement Learning</li>
            <li>Explaining Convolutional Neural Networks via Saliency Maps</li>
            <li>Unsupervised Density Estimation using Deep Autoregressive Models</li>
            <!--<li>Reformulating Trust Region Policy Optimization using Conjugate Gradient Descent</li>-->
            <li>Video Summarization using Submodular functions</li>
            <li>Domain Adaptation in Reinforcement Learning using Beta-VAE</li>
            <!--<li>Surround View for Automotive Driver Assistant Systems</li>
            <li>Human Action Recognition using Binary Motion Image and Classification</li>
            <li>Safety Diagnostic Library for ASIL-B applications</li>
            <li>Bluetooth Low Energy software stack</li>-->
          </ul>
        </p>

      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="projects">
      <div class="w-100">
        <h2 class="mb-5">Projects</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Structured Attention Graphs for Understanding Deep Image Classifications</h3>

            <br/><a class="github-button btn" href="https://github.com/viv92/structured-attention-graphs" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/structured-attention-graphs" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/structured-attention-graphs/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->
            <p class="lead mb-5">Humans can look at different occluded versions of an object and still identify the object. This project shows that even convolutional neural networks can confidently identify the image class from minimal regions of the image. The key finding is that there exist multiple sets of such minimal regions for an image. We present these regions as directed acyclic graphs (termed as SAG for "Structured Attention Graph") that provide insights into the network's classification scheme.</p>

          <figure class="sagfigs">
            <img class="sagimgs" src="img/peacock_original.png"></img>
            <figcaption>Original image</figcaption>
          </figure>

          <figure class="sagfigs">
            <img class="sagimgs" src="img/peacock_gcam.png"></img>
            <figcaption>Grad-CAM</figcaption>
          </figure>

          <figure class="sagfigs">
            <img class="sagimgs" src="img/peacock_igos.png"></img>
            <figcaption>I-GOS</figcaption>
          </figure>

          <figure class="sagfigs">
            <img class="sagimgs" src="img/peacock_dnf.gif"></img>
            <figcaption>Ours</figcaption>
          </figure>

          <figure class="sagfigs2">
            <img class="sagimgs" src="img/peacock_sag.png"></img>
            <figcaption>SAG</figcaption>
          </figure>

          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Simulation Optimization using Reinforcement Learning</h3>

            <br/><a class="github-button btn" href="https://github.com/viv92/simulopt" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/simulopt" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/simulopt/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->
            <p class="lead mb-5">Project on optimizing an industrial processes by converting it to an approximate MDP and applying model-free reinforcement learning algorithms on a discrete event simulator. Implemented in TensorFlow. Published in Winter Simulation Conference 2019.</p>

          <figure class="simuloptfigs">
            <img class="simuloptimgs" src="img/pipeline.png"></img>
            <figcaption>Architecture</figcaption>
          </figure>

          <figure class="simuloptfigs">
            <img class="simuloptimgs" src="img/researchplan.png"></img>
            <figcaption>Research Objectives</figcaption>
          </figure>

          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">XNN: Explainable Neural Network to Disentangle Visual Concepts</h3>

            <br/><a class="github-button btn" href="https://github.com/viv92/xAI-VisualConcepts" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/xAI-VisualConcepts" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/xAI-VisualConcepts/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->
            <p class="lead mb-5">XNN is a novel neural network architecture designed to yeild saliency maps that can be disentangled to represent visual concepts. Hence the generated saliency maps can be used to attribute explanations to the Neural Net's classifications. The XNN architecture uses stacked Sparse Reconstruction Autoencoders (SRAE) with a novel "concept loss", a "pull away term" and Integrated-Gradient based visualization to generate explainable saliency maps. Implemented in PyTorch.</p>

          <figure class="xnnfigs">
            <img class="xnnimgs" src="img/xnn1.png"></img>
            <figcaption>Sample Explanations Obtained</figcaption>
          </figure>

          <figure class="xnnfigs">
            <img class="xnnimgs" src="img/xnn2.png"></img>
            <figcaption>The Explanation Module</figcaption>
          </figure>

          <figure class="xnnfigs">
            <img class="xnnimgs" src="img/xnn3.png"></img>
            <figcaption>SRAE implementing the Explanation Module</figcaption>
          </figure>

          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Object Tracking and surveillance using Computer Vision</h3>
            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->

            <br/><a class="github-button btn" href="https://github.com/viv92/video-analytics" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/video-analytics" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/video-analytics/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <p class="lead mb-5">This project involves building computer vision applications for object tracking, object counting, object tampering, intrusion detection and surveillance by performing transfer learning over object localization networks such as Darknet YOLO, Faster-RCNN and MobileNet-SSD. Kalman filter based SOR Tracker was used for tracking. Developed using C++ and Caffe. </p>

            <figure class="simuloptfigs">
              <img class="trackimgs" src="img/track1.gif"></img>
              <figcaption>Person tracking and counting</figcaption>
            </figure>

            <figure class="simuloptfigs">
              <img class="trackimgs" src="img/track2.gif"></img>
              <figcaption>Classroom monitoring</figcaption>
            </figure>


          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Trust Region Policy Optimization using Conjugate Gradient Descent</h3>
            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->

            <br/><a class="github-button btn" href="https://github.com/viv92/convoptfinal" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/convoptfinal" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/convoptfinal/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <p class="lead mb-5">This work derives the Trust Region Policy Optimization (TRPO) algorithm and develops a novel online variant of TRPO using Conjugate Gradient Descent. The online variant of the algorithm is shown to optimize an Earthmoving operation as a proof-of-concept. Implemented in TensorFlow. </p>

            <figure class="simuloptfigs">
              <img class="trpoimgs" src="img/trpo1.png"></img>
              <figcaption>TRPO Algorithm</figcaption>
            </figure>

            <figure class="simuloptfigs">
              <img class="trpoimgs" src="img/trpo2.png"></img>
              <figcaption>Results on custom Earthmoving environment</figcaption>
            </figure>


          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Unsupervised Density Estimation using Deep Autoregressive Models</h3>
            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->

            <br/><a class="github-button btn" href="https://github.com/viv92/Deep-Autoregressive-Model" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/Deep-Autoregressive-Model" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/xDeep-Autoregressive-Model/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <p class="lead mb-5">This work explores deep autoregressive models for density estimation such as Neural Autoregressive Density Estimator (NADE) and Masked Autoregressive Density Estimation (MADE). The hypothesis is that deep autoregressive models such as MADE generate richer samples than those generated by mixture models such as GMM, verified by the samples generated for the Anime Faces dataset. Implemented in PyTorch. </p>

            <figure class="simuloptfigs">
              <img class="madeimgs" src="img/made1.png"></img>
              <figcaption>MADE Architecture</figcaption>
            </figure>

            <figure class="simuloptfigs">
              <img class="madeimgs" src="img/made2.png"></img>
              <figcaption>Results on Anime Faces</figcaption>
            </figure>


          </div>
        </div>


        <!--<div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Domain Adaptation in Reinforcement Learning using Abstract Representations</h3>
            <div class="subheading mb-3">Intelitec Solutions</div>

            <br/><a class="github-button btn" href="https://github.com/viv92/deer" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/deer" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/deer/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <p class="lead mb-5">This project extends the work on Combined Reinforcement Learning via Abstract Representations [1] to include domain adaptation across different environments. This is achieved by modifying the architecture of the learning problem in order to enable learning of  common abstractions over multiple environments. Implemented in PyTorch.</p>

            <figure class="simuloptfigs">
              <img class="crarimgs" src="img/crar1.png"></img>
              <figcaption>Architecture of the learning problem</figcaption>
            </figure>

            <figure class="simuloptfigs">
              <img class="crarimgs" src="img/crar2.png"></img>
              <figcaption>Abstract representation learnt for Catcher environment</figcaption>
            </figure>


          </div>
        </div>-->


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Video Summarization using Submodular Functions</h3>
            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->

            <br/><a class="github-button btn" href="https://github.com/viv92/vis-dss" data-size="large" data-show-count="false" aria-label="cloud-cv/evalai on GitHub">Code</a>
            <a class="github-button" href="https://github.com/viv92/vis-dss" data-icon="octicon-star" data-size="large" data-show-count="false" aria-label="Star cloud-cv/evalai on GitHub">Star</a>
            <a class="github-button" href="https://github.com/viv92/vis-dss/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="false" aria-label="Fork cloud-cv/evalai on GitHub">Fork</a><br/>

            <p class="lead mb-5">This is a toolkit developed to perform Visual Data Subset Selection and Visual Data Summarization Using Submodular Functions. The toolkit employs several summarization models that perform Feature Subset Selection based on Diversity Functions, Coverage Functions and Representation Functions. One of the following three summarization algorithms can be used: Budgeted Greedy, Stream Greedy and Coverage Greedy. Developed in C++. </p>

            <figure class="xnnfigs">
              <img class="xnnimgs" src="img/summary1.png"></img>
              <figcaption>Selection based on Diversity Functions</figcaption>
            </figure>

            <figure class="xnnfigs">
              <img class="xnnimgs" src="img/summary2.png"></img>
              <figcaption>Selection based on Representation Functions</figcaption>
            </figure>

            <figure class="xnnfigs">
              <img class="xnnimgs" src="img/summary3.png"></img>
              <figcaption>Selection based on Coverage Functions</figcaption>
            </figure>


          </div>
        </div>


      </div>
    </section>


    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="publications">
      <div class="w-100">
        <h2 class="mb-5">Publications</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Structured Attention Graphs for Understanding Deep Image Classifications</h3>
            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->
            <p class="lead mb-5">
              <b>Vivswan Shitole</b>, Li Fuxin, Minsuk Kahng, Prasad Tadepalli, Alan Fern
              <br/>
              <i><a href="https://arxiv.org/pdf/2011.06733" target="_blank">arxiv:2011.06733</a></i>
            </p>

            <a href="https://arxiv.org/pdf/2011.06733" target="_blank"><img class="pubimgs" src="img/pub_sag.jpg"></img></a>

          </div>

        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Optimizing Earthmoving Operations via Reinforcement Learning</h3>
            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->
            <p class="lead mb-5">
              <b>Vivswan Shitole</b>, Joseph Louis, Prasad Tadepalli
              <br/>
              <i>Winter Simulation Conference 2019</i>
            </p>

            <a href="https://ieeexplore.ieee.org/document/9004935" target="_blank"><img class="pubimgs" src="img/pub2.jpg"></img></a>

          </div>

        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Human Activity Recognition using Binary Motion Image and Deep Learning</h3>
            <!--<div class="subheading mb-3">Intelitec Solutions</div>-->
            <p class="lead mb-5">
              Tushar Dobhal, <b>Vivswan Shitole</b>, Gabriel Thomas, Girisha Navada
              <br/>
              <i>Procedia Computer Science, Elsevier 2015</i>
            </p>

            <a href="http://www.sciencedirect.com/science/article/pii/S1877050915021614" target="_blank"><img class="pubimgs" src="img/pub1.png"></img></a>

          </div>

        </div>


      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="experience">
      <div class="w-100">
        <h2 class="mb-5">Experience</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Machine Learning Engineer</h3>
            <div class="subheading mb-3">AITOE Labs</div>

            <p class="lead mb-5">◾️ Worked on developing several computer vision applications for video analytics and surveillance. This involved customizing the following computer vision algorithms and deep learning models for our specific usecases:
            <ul class="body_ul">
              <li>Background subtraction: MOG, GMG, MLBGS</li>
              <li>Face detection: NPD, Dlib Frontal Face Detector</li>
              <li>Face recognition: OpenFace, Custom VGG model obtained by transfer learning</li>
              <li>Head detection: HAAR cascade classifier</li>
              <li>Human detection: HOG, ICF, DPM</li>
              <li>Object recognition: Custom Darknet-Yolo model obtained by transfer learning</li>
            </ul>
            </p>

            <p class="lead mb-5">◾️ Created an ”object tracker” using Kalman filter based SOR tracking to estimate traffic and detect intrusions through surveillance videos at crowded public places in Mumbai.</p>

          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">July 2017 - April 2018</span><br/>
            <img class="company_logo" src="img/aitoe.png"></img>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Research Intern</h3>
            <div class="subheading mb-3">IIT Bombay</div>
            <p class="lead mb-5">◾️ Created a ”classroom monitor” used to mark attendance and detect anomalous events in classrooms through surveillance cameras deployed in some rural schools of Mumbai with the help of NCETIS. This involved training custom Mobilenet-SSD and Darknet-Yolo models for face and apparel recognition using Caffe and building a software around it.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">May 2017 - July 2017</span><br/>
            <img class="company_logo" src="img/iitb.png"></img>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Software Design Engineer</h3>
            <div class="subheading mb-3">Texas Instruments</div>
            <p class="lead mb-5">◾️ Developed SafeTI Diagnostic Library for functional safety of TI’s safety critical microcontrollers deployed in ASIL B applications.</p>
            <p class="lead mb-5">◾️ Developed API for GAP, GATT and Security Manager layers of Bluetooth Low Energy software stack for TI’s ultra low power microcontrollers</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">August 2015 - October 2016</span><br/>
            <img class="company_logo" src="img/ti.png"></img>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
          <div class="resume-content">
            <h3 class="mb-0">Project Trainee</h3>
            <div class="subheading mb-3">Texas Instruments</div>
            <p class="lead mb-5">◾️ Worked on Camera Synchronization for ADAS Automobile Camera Systems connected to host using FPD link based on LVDS standard, used in various application scenarios like surround view, stereo vision and multi-camera fusion for redundancy.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">May 2014 - July 2014</span><br/>
            <img class="company_logo" src="img/ti.png"></img>
          </div>
        </div>

      </div>

    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="education">
      <div class="w-100">
        <h2 class="mb-5">Education</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Oregon State University</h3>
            <div class="subheading mb-3">Master of Science</div>
            <p class="lead mb-5">Computer Science - Artificial Intelligence Track<br/>
            GPA: 3.85</p>
            <p class="lead mb-5">Relevant Courses:
            <ul class="body_ul" style="list-style-type:square">
              <li>CS 534. Machine Learning</li>
              <li>CS 531. Artificial Intelligence</li>
              <li>CS 536. Probabilistic Graphical Models</li>
              <li>CS 519. Convex Optimization</li>
              <li>CS 533. Intelligent Agents</li>
              <li>CS 519. Algorithms Design and Analysis</li>
              <li>ROB 567. Human-Robot Interaction</li>
              <li>CS539. Embodied AI</li>
            </ul>
            </p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">Sep 2018 - Present</span><br/>
            <img class="company_logo" src="img/osu.png"></img>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
          <div class="resume-content">
            <h3 class="mb-0">National Institute of Technology Karnataka</h3>
            <div class="subheading mb-3">Bachelor of Technology</div>
            <p class="lead mb-5">Electrical and Electronics<br/>
              GPA: 3.3</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">Aug 2011 - May 2015</span><br/>
            <img class="company_logo" src="img/nitk.png"></img>
          </div>
        </div>

      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="skills">
      <div class="w-100">
        <h2 class="mb-5">Skills</h2>

        <div class="subheading mb-3">Programming Languages &amp; Tools</div>
        <ul class="list-inline dev-icons">
          <li class="list-inline-item">
            <img class="tech_logo" src="img/python.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/tensorflow.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/caffe.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/pytorch.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/cuda.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/keras.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/c.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/cpp.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/sql.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/js.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/php.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/html5.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/css3.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/java.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/r.png"></img>
          </li>
          <li class="list-inline-item">
            <img class="tech_logo" src="img/matlab.png"></img>
          </li>
        </ul>

        <!--<div class="subheading mb-3">Workflow</div>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-check"></i>
            Mobile-First, Responsive Design</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Cross Browser Testing &amp; Debugging</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Cross Functional Teams</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Agile Development &amp; Scrum</li>
        </ul>-->

      </div>
    </section>

    <hr class="m-0">

    <!-- <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="interests">
      <div class="w-100">
        <h2 class="mb-5">Interests</h2>
        <p>Apart from being a web developer, I enjoy most of my time being outdoors. In the winter, I am an avid skier and novice ice climber. During the warmer months here in Colorado, I enjoy mountain biking, free climbing, and kayaking.</p>
        <p class="mb-0">When forced indoors, I follow a number of sci-fi and fantasy genre movies and television shows, I am an aspiring chef, and I spend a large amount of my free time exploring the latest technology advancements in the front-end web development world.</p>
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="awards">
      <div class="w-100">
        <h2 class="mb-5">Awards &amp; Certifications</h2>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Google Analytics Certified Developer</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Mobile Web Specialist - Google Certification</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1<sup>st</sup>
            Place - University of Colorado Boulder - Emerging Tech Competition 2009</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1<sup>st</sup>
            Place - University of Colorado Boulder - Adobe Creative Jam 2008 (UI Design Category)</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            2<sup>nd</sup>
            Place - University of Colorado Boulder - Emerging Tech Competition 2008</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            1<sup>st</sup>
            Place - James Buchanan High School - Hackathon 2006</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            3<sup>rd</sup>
            Place - James Buchanan High School - Hackathon 2005</li>
        </ul>
      </div>
    </section> -->

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>

</html>
